{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd1824b",
   "metadata": {},
   "source": [
    "# Notebook 01 — EDA & Cleaning (Days 1–2)\n",
    "\n",
    "This notebook performs data loading, filtering to 2-3 bedroom apartments, cleaning, exploratory data analysis, missing-value treatment, outlier detection, and saves a stage-1 cleaned dataset and EDA artifacts under `outputs/01_eda/`.  \n",
    "\n",
    "**Run this notebook start-to-finish.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c44478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and setup\\n\\nimport warnings\n",
    "warnings.filterwarnings('ignore')\\n\\nimport numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\\n\\nRND = 42\n",
    "np.random.seed(RND)\\n\\nDATA_PATH = Path(r'/mnt/data/cairo_real_estate_dataset.csv')\\n\\nOUT_DIR = Path('outputs/01_eda')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\\n\\nprint('Looking for dataset at', DATA_PATH)\\n\\nif not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}. Please upload cairo_real_estate_dataset.csv to /mnt/data/.\")\\n\\ndf = pd.read_csv(DATA_PATH, parse_dates=['listing_date'], dayfirst=True)\n",
    "print('Original shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2110092",
   "metadata": {},
   "source": [
    "## Basic cleaning and type standardization\n",
    "- Convert Yes/No/TrueFalse booleans to 0/1\n",
    "- Standardize categorical text fields\n",
    "- Filter to 2-3 bedroom apartments (target population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize boolean-like columns and basic text fields\n",
    "bool_cols = ['has_balcony','has_parking','has_security','has_amenities','is_negotiable']\n",
    "for c in bool_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(str).str.strip().str.lower().map({'yes':1,'no':0,'true':1,'false':0,'1':1,'0':0})\n",
    "\n",
    "if 'seller_type' in df.columns:\n",
    "    df['seller_type'] = df['seller_type'].astype(str).str.strip().str.title()\n",
    "if 'finishing_type' in df.columns:\n",
    "    df['finishing_type'] = df['finishing_type'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Filter to 2-3 bedrooms\n",
    "if 'bedrooms' in df.columns:\n",
    "    before = df.shape[0]\n",
    "    df = df[df['bedrooms'].isin([2,3])].copy()\n",
    "    print(f'Filtered from {before} rows to {df.shape[0]} rows (2-3 bedrooms)')\n",
    "else:\n",
    "    print('No bedrooms column found; proceeding without filter')\n",
    "\n",
    "# Numeric coercion and derived features\n",
    "for col in ['area_sqm','price_egp']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "if 'area_sqm' in df.columns and 'price_egp' in df.columns:\n",
    "    df.loc[df['area_sqm'] <= 0, 'area_sqm'] = pd.NA\n",
    "    df['price_per_sqm'] = df['price_egp'] / df['area_sqm']\n",
    "\n",
    "if 'listing_date' in df.columns:\n",
    "    df['listing_month'] = df['listing_date'].dt.month\n",
    "    df['listing_year'] = df['listing_date'].dt.year\n",
    "\n",
    "print('After typing and derived features, shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a9b6b",
   "metadata": {},
   "source": [
    "## Missing value summary and data quality plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values summary\n",
    "mv = pd.DataFrame({'n_missing': df.isnull().sum(), 'pct_missing': df.isnull().mean()}).sort_values('pct_missing', ascending=False)\n",
    "mv.to_csv(OUT_DIR / 'missing_values_summary.csv', index=True)\n",
    "print(mv.head(20))\n",
    "\n",
    "# Data quality plan (initial)\n",
    "plan = []\n",
    "for col in df.columns:\n",
    "    plan.append({'column': col, 'n_missing': int(df[col].isnull().sum()), 'pct_missing': float(df[col].isnull().mean()), 'proposal': 'investigate and impute/drop/encode'})\n",
    "plan_df = pd.DataFrame(plan).sort_values('pct_missing', ascending=False)\n",
    "plan_df.to_csv(OUT_DIR / 'data_quality_plan.csv', index=False)\n",
    "print('Saved missing value summary and data quality plan to', OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c90cb",
   "metadata": {},
   "source": [
    "## Exploratory plots\n",
    "Saved figures: price distribution, price_per_sqm boxplot, numeric correlation heatmap, top districts and finishing types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55078d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric columns exist\n",
    "num_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Price histogram\n",
    "if 'price_egp' in df.columns:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(df['price_egp'].dropna(), bins=60)\n",
    "    plt.title('Price distribution')\n",
    "    plt.xlabel('Price (EGP)')\n",
    "    plt.savefig(OUT_DIR / 'price_hist.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Price per sqm boxplot\n",
    "if 'price_per_sqm' in df.columns:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.boxplot(x=df['price_per_sqm'].dropna())\n",
    "    plt.title('Price per sqm boxplot')\n",
    "    plt.savefig(OUT_DIR / 'pps_box.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Correlation heatmap\n",
    "if len(num_cols) > 1:\n",
    "    corr = df[num_cols].corr()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "    plt.title('Numeric correlation matrix')\n",
    "    plt.savefig(OUT_DIR / 'corr_matrix.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Categorical counts\n",
    "if 'district' in df.columns:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    df['district'].value_counts().head(20).plot(kind='bar')\n",
    "    plt.title('Top districts (counts)')\n",
    "    plt.savefig(OUT_DIR / 'district_counts.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "if 'finishing_type' in df.columns:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    df['finishing_type'].value_counts().plot(kind='bar')\n",
    "    plt.title('Finishing type counts')\n",
    "    plt.savefig(OUT_DIR / 'finishing_counts.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print('Saved EDA figures to', OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a82f0b",
   "metadata": {},
   "source": [
    "## Outlier detection\n",
    "- Use robust thresholds (1st and 99th percentiles) for price_per_sqm\n",
    "- Mark outliers but keep them for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51608778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier marking\n",
    "if 'price_per_sqm' in df.columns:\n",
    "    q1 = df['price_per_sqm'].quantile(0.01)\n",
    "    q99 = df['price_per_sqm'].quantile(0.99)\n",
    "    df['pps_outlier'] = ((df['price_per_sqm'] < q1) | (df['price_per_sqm'] > q99)).astype(int)\n",
    "    print('price_per_sqm 1%:', q1, '99%:', q99)\n",
    "\n",
    "# Area outliers\n",
    "if 'area_sqm' in df.columns:\n",
    "    df['area_outlier'] = ((df['area_sqm'] < 25) | (df['area_sqm'] > 500)).astype(int)\n",
    "\n",
    "# Save stage1 cleaned dataset\n",
    "DATA_DIR = Path('data')\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_PATH = DATA_DIR / 'cleaned_df_stage1.parquet'\n",
    "df.to_parquet(CLEAN_PATH, index=False)\n",
    "print('Saved stage1 cleaned dataset to', CLEAN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038355f5",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "Proceed to Notebook 02 to build preprocessors and baseline models. The stage1 cleaned file is saved to `data/cleaned_df_stage1.parquet`."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
